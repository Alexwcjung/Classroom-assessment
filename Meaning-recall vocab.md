# ğŸ¤– Stewart et al. (2025)
**Can we reliably score meaning-recall vocabulary tests using AI?**  
*(Language Testing, in press)*

---

## ğŸ§­ Introduction

Traditional vocabulary tests often rely on **meaning-recognition formats** (e.g., multiple-choice), which are efficient but can inflate scores through guessing.  

**Meaning-recall tests**, by contrast, tap into real productive vocabulary knowledge but are time-consuming and require trained human ratersâ€”especially for multilingual responses.  

With advances in **Large Language Models (LLMs)** such as *GPT-4* and *Gemini*, AI-based scoring may now achieve human-like semantic judgment and reliability.

---

## â“ Research Questions

**RQ1.** Are LLM ratings stricter, more lenient, or statistically indistinguishable from human ratings?  
â†’ Compare mean scores and rater severity between human and LLM scoring using Many-Facet Rasch Measurement (MFRM).

**RQ2.** Does scoring meaning-recall vocabulary tests with LLMs affect reliability compared to human scoring?  
â†’ Examine internal consistency (Cronbachâ€™s Î±) and score variance to determine whether AI scoring yields comparable reliability.

**RQ3.** Are correlations between human and LLM ratings acceptable under inter-rater reliability standards?  
â†’ Evaluate Pearson and intraclass correlations to see if Humanâ€“AI agreement matches humanâ€“human benchmarks.

**RQ4.** When and why do LLM and human raters differ in their judgments?  
â†’ Identify items with significant Humanâ€“AI disagreement and analyze whether differences stem from categorical errors or natural rater leniency.


## ğŸ“š Background
* **Recognition tests:** efficient but they may fail to fully reflect a learnerâ€™s true ability.
* **Recall tests:** more valid but labor-intensive to score.  
* **LLMs:** show strong *contextual and semantic matching* (Aryadoust 2023; Roever 2024).  
- Empirical evidence comparing **human vs. AI reliability** is still limited.  
- This study examines whether AI scoring can achieve **fairness, validity, and consistency** comparable to human assessment.

---

## âš™ Method (ë°©ë²•)
| êµ¬ë¶„ | ë‚´ìš© |
|------|------|
| **Participants** | ì¼ë³¸ EFL í•™ìŠµì 611ëª… (18â€“22ì„¸, ì˜ì–´ í•™ìŠµ 6ë…„ ì´ìƒ) |
| **Test Design** | Meaning recall vocabulary test (150 ë‹¨ì–´, BNC/COCA 1Kâ€“5K ìˆ˜ì¤€). ì°¸ê°€ìëŠ” ê° ì˜ì–´ ë‹¨ì–´ì˜ ì¼ë³¸ì–´ ì˜ë¯¸ ì‘ì„±. |
| **Raters** | ğŸ‘©â€ğŸ« Human 2 ëª… (ì˜ì¼ ì´ì¤‘ì–¸ì–´ ì±„ì ì)  ğŸ¤– AI 3 ì¢… (GPT-4o, Gemini 1.5, Llama 3-8B) |
| **Scoring Scheme** | Binary (1 = correct, 0 = incorrect). Prompt: â€œDoes this Japanese response convey the correct meaning of the English word?â€ |
| **Analysis** | ê¸°ìˆ í†µê³„ + Many-Facet Rasch Measurement (MFRM), Cronbachâ€™s Î±, Pearson r, ICC (ì±„ì ìê°„ ì‹ ë¢°ë„). |

---

## ğŸ“Š Results (ê²°ê³¼)
| í•µì‹¬ ê²°ê³¼ | ìš”ì•½ ë° í†µê³„ |
|------------|--------------|
| **í‰ê·  ì ìˆ˜ íŒ¨í„´** | Gemini (75.3) > Human1 (73.8) â‰ˆ GPT (71.5) â‰ˆ Human2 (70.2) > Llama (64.7). â†’ GPT/Gemini â‰ˆ ì¸ê°„ ìˆ˜ì¤€. |
| **Reliability** | Cronbachâ€™s Î± â‰ˆ .96 (GPT & Gemini = Human-level). Llama ì•½ê°„ ë‚®ìŒ. |
| **Humanâ€“AI correlation** | r > .95, ICC > .90 â†’ â€œExcellent agreement.â€ |
| **Strictness trend** | Llama ê°€ ê°€ì¥ ë³´ìˆ˜ì  (ë‚®ì€ í‰ê·  ì ìˆ˜ ë° ë¶„ì‚°). |
| **Error patterns** | ë‹¤ì˜ì–´Â·L1-transfer ì˜ë¯¸ (ì˜ˆ: *develop, clinic, random*) ì—ì„œ AI ì˜¤íŒ ì‚¬ë¡€ ê´€ì°°. |

---

## ğŸŒˆ Interpretation (í•´ì„)
* **GPT-4o & Gemini 1.5** â†’ human-like accuracy and consistency.  
* **Llama 3-8B** â†’ parameters ì ì–´ ë³´ìˆ˜ì  ì±„ì  ê²½í–¥.  
* **AI scoring patterns â‰ˆ human judgment**, low-stakes í‰ê°€ ì— í™œìš© ê°€ëŠ¥.  
* ì°¨ì´ëŠ” ì£¼ë¡œ **polysemous words** ë° **L1 ì˜ë¯¸ ì „ì´** ìƒí™©ì—ì„œ ë°œìƒ.  

---

## ğŸ’¬ Discussion & Implications
* **Fairness ê³µì •ì„±:** ëª…í™•í•œ ê¸°ì¤€ prompt ì„¤ê³„ ì‹œ AI ë„ ê³µì •ì„± ìœ ì§€ ê°€ëŠ¥.  
* **Efficiency íš¨ìœ¨ì„±:** 600ëª… ì±„ì  â†’ Human ì•½ 5ì‹œê°„ vs GPT 10ë¶„ ë¯¸ë§Œ.  
* **Use cases:** í˜•ì„±í‰ê°€, ì—°ìŠµ or ëŒ€ê·œëª¨ ì €ìœ„í—˜ ì‹œí—˜ì— ì í•©.  
* **Future work:** (1) Human-AI hybrid ëª¨ë¸ ë³´ì •  (2) ë‹¤ì–¸ì–´ í™•ì¥  (3) ë°˜ë³µì±„ì  ì¼ê´€ì„± ê²€ì¦.  

---

## ğŸ§© Conclusion (ê²°ë¡ )
âœ… **GPT-4o and Gemini achieve human-level reliability and accuracy.**  
âš™ï¸ **AI-based meaning-recall scoring** is feasible for large-scale or low-stakes testing.  
ğŸš§ High-stakes contexts require hybrid systems and continued validation.  

---

## ğŸ’¬ Discussion Questions
1. Should LLMs replace human raters in classroom vocabulary assessment?  
2. How can teachers ensure fairness for learners with different L1 backgrounds?  
3. How might AI feedback promote *construct-relevant learning* rather than *test-wiseness*?  
