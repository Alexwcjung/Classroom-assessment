# **Exploring the Potential of  Conversational AI for Assessing Second  Language Oral Proficiency**  

---

# ğŸŒ³ Research Topic & Need

## **Research Topic**
This study examines whether a conversational AIâ€“based Spoken Dialogue System (SDS) can:
- elicit **Interactional Competence (IC)** from L2 speakers, and  
- provide an **authentic and effective** speaking test experience.

## **Research Need**
- **IC (interactional competence)** is a core part of oral proficiency but is not assessed in most large-scale computer-based English tests.  
- Tests like **TOEFL, Versant, Duolingo** are largely monologic â†’ **cannot assess IC**.  
- Human examiner interviews are **costly**, **inconsistent**, and affected by **interlocutor idiosyncrasies**.  
- SDS has potential to combine **standardization + interactiveness**.

## **Research Questions (Official RQs in the Paper)**

**RQ1:** *What types of interactive language functions are elicited by the SDS, and how frequently do these functions appear in test-taker responses?*

**RQ2:** *What are test takersâ€™ perceptions of the SDS-mediated speaking test in terms of authenticity and effectiveness?*

---

# ğŸŒ³ Background: Interactional Competence (IC)

IC refers to the ability to co-construct real-time conversation.  
Key components include:

- managing turn-taking  
- repairing misunderstandings and overlaps  
- opening and closing conversations  
- maintaining alignment through politeness  
- adjusting speech based on the interlocutorâ€™s status and shared knowledge  
- providing backchannels (e.g., *yeah, right, wow* + facial expressions, eye contact, head nods)  
- managing topics  
- behaving in accordance with one's social role  

â†’ Essential in real communication but often **not measured** in computer-based tests.

---

# ğŸŒ³ Method

## **Participants**
- 30 adult L2 English learners  
- 10 joined follow-up interviews  
- All performances rated by two trained human raters (IELTS scale)

## Procedure
1. **SDSê°€ IELTS Speaking ì‹œí—˜ê´€(examiner) ì—­í• ì„ ìˆ˜í–‰**  
   - í•™ìŠµìëŠ” ì‚¬ëŒ ëŒ€ì‹  AIì™€ face-to-face ì²˜ëŸ¼ ëŒ€í™”. AIê°€ ì§ˆë¬¸í•˜ê³ , ì´ì–´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ follow-up ì§ˆë¬¸ì„ ë˜ì§€ëŠ” êµ¬ì¡°   
2. Learners engage in real-time interaction with SDS.  
3. ëª¨ë“  ëŒ€í™”ëŠ” ë…¹ìŒ ë° ì „ì‚¬(transcription)ë¨  
4. ì¸ê°„ í‰ê°€ìê°€ ë…¹ìŒë³¸ì„ ë“£ê³  ì±„ì   
5. Researchers analyze:
   - IC features and frequency  
   - Learner perceptions (authenticity, comfort, difficulty)  

## Data Sources  

- **Interaction transcripts** â†’ IC ìš”ì†Œ(turn-taking, clarification ë“±) ì½”ë”©  
- **Human rating scores** â†’ í‰ê°€ì ì¼ì¹˜ë„ ë¶„ì„  
- **Post-test interviews** â†’ ìì—°ìŠ¤ëŸ¬ì›€Â·ë‚œì´ë„Â·í¸ì•ˆí•¨ ë“± í”¼ë“œë°±  
- **IC coding scheme** â†’ established IC research ê¸°ë°˜  
â†’ *ì •ì„±(ëŒ€í™” ë¶„ì„) + ì •ëŸ‰(í‰ê°€ì ì ìˆ˜) í˜¼í•©ì˜ mixed-methods ì—°êµ¬*

---

# ğŸŒ³ Results

## **RQ1 â€” IC features elicited by SDS**
### âœ” Summary
SDS successfully elicited **core IC features**, and these behaviors helped **distinguish proficiency levels**.  

### **1) Turn-taking**
- All learners engaged in **normal, reciprocal turn-taking** with SDS.  
- Higher-proficiency speakers often produced **longer turns (ì•½ 20â€“30% ë” ê¸¸ê²Œ)** or brief expansions.  
  - *â€œI think one challengeâ€¦ and another thing isâ€¦â€*

### **2) Clarification & Repair**
- Learners used clarification requests:
  - *â€œSorry, could you repeat that?â€*  
- Higher-level learners showed more natural **self-repair**:
  - *â€œI thinkâ€¦ I mean, the main reason isâ€¦â€*

### **3) Topic Management**
- Learners maintained SDS-initiated topics effectively.  
- Advanced learners expanded topics:
  - *â€œAnother important point isâ€¦â€*

### RQ1 Conclusion
- SDS-generated interactions formed **valid, assessable samples**.

---

## **RQ2 â€” Test-Taker Perceptions of SDS**

### âœ” Summary
Learners generally evaluated SDS as **competent and reliable**, but noted a lack of **human-like naturalness**.

### Positive Perceptions
- **Competent and consistent**: SDS asked clear, predictable questions.  
- **Reduced anxiety**: Learners felt less pressure than with human examiners.  
- **Enjoyment**: Some learners found the AI interaction fun and comfortable.

### Negative Perceptions
- **Lack of naturalness**: No nonverbal cues such as eye contact or facial expressions.  
- **Occasional interruptions**: Sudden topic shifts or unnatural timing.  
- **Preference for humans**: Learners still favored human interviewers for richer, more natural interaction.

### RQ2 Conclusion
- Learners viewed the SDS as efficient and low-stress, but its limited naturalness led many to still prefer human interlocutors.

---
# ğŸŒ³ Implications
- SDS can supplement or partially replace human examiners in speaking assessments.    
- Valid sample ì œê³µ + ë†’ì€ í‘œì¤€í™”  
- ê°œì„  í•„ìš”: multimodal cues (í‘œì •Â·ì‹œì„ Â·ì œìŠ¤ì²˜), ì •í™•í•œ ì¸ì‹, ë” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„  
- êµìœ¡Â·í‰ê°€ ë¶„ì•¼ì—ì„œ AI í™œìš© ê°€ëŠ¥ì„± ì¦ê°€

---

# ğŸŒ³ Teacher Discussion Questions

1. SDSë¥¼ í™œìš©í•œ êµì‹¤ ë§í•˜ê¸° í™œë™ì€ ì–´ë–¤ ê²ƒì´ ìˆì„ê¹Œ?
2. AI SDSê°€ ì¸ê°„ ì‹œí—˜ê´€ì„ ì™„ì „íˆ ëŒ€ì²´í•  ìˆ˜ ìˆì„ê¹Œ?


